@article{kolmogorov1941,
	title = {The {Local} {Structure} of {Turbulence} in {Incompressible} {Viscous} {Fluid} for {Very} {Large} {Reynolds}' {Numbers}},
	volume = {30},
	issn = {0002-3264},
	url = {https://ui.adsabs.harvard.edu/abs/1941DoSSR..30..301K},
	urldate = {2024-05-13},
	journal = {Akademiia Nauk SSSR Doklady},
	author = {Kolmogorov, A.},
	month = jan,
	year = {1941},
	note = {ADS Bibcode: 1941DoSSR..30..301K},
	pages = {301--305},
}

@book{priest2000,
	title = {Magnetic {Reconnection}: {MHD} {Theory} and {Applications}},
	shorttitle = {Magnetic {Reconnection}},
	url = {https://ui.adsabs.harvard.edu/abs/2000mare.book.....P},
	abstract = {Magnetic reconnection is at the core of many dynamic phenomena in the universe, such as solar flares, geomagnetic substorms and tokamak disruptions. Written by two world leaders on the subject, this volume provides a comprehensive overview of this fundamental process. Coverage gives both a pedagogical account of the basic theory and a wide-ranging review of the physical phenomena created by reconnection--from laboratory machines, the Earth's magnetosphere, and the Sun's atmosphere to flare stars and astrophysical accretion disks. It also includes a succinct account of particle acceleration by electric fields, stochastic fields and shock waves, and how reconnection can be important in these mechanisms. Clearly written and highly accessible, this volume serves as an essential introduction for graduate students in solar physics, astrophysics, plasma physics and space science. Researchers in these fields also will find Magnetic Reconnection an authoritative reference.},
	urldate = {2024-09-02},
	author = {Priest, Eric and Forbes, Terry},
	month = jun,
	year = {2000},
	doi = {10.1017/CBO9780511525087},
	note = {Publication Title: Magnetic Reconnection: MHD Theory and Applications
ADS Bibcode: 2000mare.book.....P},
}

@ARTICLE{lemoine2023,
       author = {{Lemoine}, Martin},
        title = "{Particle transport through localized interactions with sharp magnetic field bends in MHD turbulence}",
      journal = {Journal of Plasma Physics},
     keywords = {astrophysical plasmas, Physics - Plasma Physics, Astrophysics - High Energy Astrophysical Phenomena},
         year = 2023,
        month = sep,
       volume = {89},
       number = {5},
          eid = {175890501},
        pages = {175890501},
          doi = {10.1017/S0022377823000946},
archivePrefix = {arXiv},
       eprint = {2304.03023},
 primaryClass = {physics.plasm-ph},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2023JPlPh..89e1701L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{zhdankin2013,
	title = {{STATISTICAL} {ANALYSIS} {OF} {CURRENT} {SHEETS} {IN} {THREE}-{DIMENSIONAL} {MAGNETOHYDRODYNAMIC} {TURBULENCE}},
	volume = {771},
	issn = {0004-637X},
	url = {https://iopscience.iop.org/article/10.1088/0004-637X/771/2/124/meta},
	doi = {10.1088/0004-637X/771/2/124},
	language = {en},
	number = {2},
	urldate = {2024-03-30},
	journal = {The Astrophysical Journal},
	author = {Zhdankin, Vladimir and Uzdensky, Dmitri A. and Perez, Jean C. and Boldyrev, Stanislav},
	month = jun,
	year = {2013},
	note = {Publisher: IOP Publishing},
	pages = {124},
}

@article{kadowaki2018,
	title = {{MHD} {Instabilities} in {Accretion} {Disks} and {Their} {Implications} in {Driving} {Fast} {Magnetic} {Reconnection}},
	volume = {864},
	issn = {0004-637X},
	url = {https://dx.doi.org/10.3847/1538-4357/aad4ff},
	doi = {10.3847/1538-4357/aad4ff},
	language = {en},
	number = {1},
	urldate = {2024-07-31},
	journal = {The Astrophysical Journal},
	author = {Kadowaki, Luis H. S. and Pino, Elisabete M. De Gouveia Dal and Stone, James M.},
	month = aug,
	year = {2018},
	note = {Publisher: The American Astronomical Society},
	pages = {52},
}

@inproceedings{hamel2019,
	address = {Cham},
	title = {{VSOM}: {Efficient}, {Stochastic} {Self}-organizing {Map} {Training}},
	isbn = {978-3-030-01057-7},
	shorttitle = {{VSOM}},
	doi = {10.1007/978-3-030-01057-7_60},
	abstract = {Here we introduce VSOM, an efficient implementation of stochastic training for self-organizing maps. We derive VSOM from the standard stochastic training algorithm as published by Kohonen by replacing all iterative constructs in the algorithm with vector and matrix operations. Our novel implementation based on these vector and matrix operations provides substantial performance increases over Kohonen’s iterative algorithm as well as batchSOM, currently the fastest implementation of Self-organizing maps (SOM) training without resorting to multi-processing. The quality of the maps produced by VSOM matches the quality of the maps produced by the original iterative algorithm and outperforms the quality of the maps produced by batchSOM. In its current incarnation VSOM is single threaded and therefore well suited as a replacement for iterative stochastic training of self-organizing maps in R since R does not support multi-threading well.},
	language = {en},
	booktitle = {Intelligent {Systems} and {Applications}},
	publisher = {Springer International Publishing},
	author = {Hamel, Lutz},
	editor = {Arai, Kohei and Kapoor, Supriya and Bhatia, Rahul},
	year = {2019},
	pages = {805--821},
}

@thesis{yuan2018,
	title = {Implementation of {Self}-{Organizing} {Maps} with {Python}},
	url = {https://digitalcommons.uri.edu/theses/1244},
	abstract = {As a member of Artificial Neural Networks, Self-Organizing Maps (SOMs) have been well researched since 1980s, and have been implemented in C, Fortran, R [1] and Python [2]. Python is an efficient high-level language widely used in the machine learning field for years, but most of the SOM-related packages which are written in Python only perform model construction and visualization. However, the POPSOM package, written in R, is capable of performing functionality beyond model construction and visualization, such as evaluating the model’s quality with statistical methods and plotting marginal probability distributions of the neurons. In order to give the Python user the POPSOM package’s advantages, it is important to migrate the POPSOM package to be Python-based. This study shows the details of this implementation.
There are three major tasks for the implementation: 1) Migrate the POPSOM package from R to Python; 2) Refactor the source code from procedural programming paradigm to object-oriented programming paradigm; 3) Improve the package by adding normalization options to the model construction function. In addition to constructing the model in Python, Fortran is also embedded to accelerate the speed of model construction significantly in this project.
The final program has been completed, and it is necessary to guarantee the correctness of the program. The best way to achieve this goal is to compare the output of the Python-based program to the output generated by the R-based program. For the model construction function, the SOM algorithm initializes the weight vector of the neurons randomly at the very beginning, and then selects the input vectors randomly during the training. Due to these two random factors, one cannot expect the same input (data set) will result in exactly the same output (neurons). Instead, to give evidence that the Python program is working properly, there are two solutions that have been proposed and applied in this project: 1) measuring the average difference of vectors between two neurons which have been generated by the R and Python functions respectively; 2) measuring the ratio of the variances and the difference of features’ mean for the two neurons. Besides the model construction, model visualization and other functions which take neurons as their input should return the same results by feeding the same input (neurons). The detail of above verification will be represented in the following chapters.},
	language = {en},
	urldate = {2024-09-24},
	school = {University of Rhode Island},
	author = {Yuan, Li},
	year = {2018},
	doi = {10.23860/thesis-yuan-li-2018},
}

@article{bussov2021,
	title = {Segmentation of turbulent computational fluid dynamics simulations with unsupervised ensemble learning},
	volume = {99},
	issn = {0923-5965},
	url = {https://www.sciencedirect.com/science/article/pii/S0923596521002150},
	doi = {10.1016/j.image.2021.116450},
	abstract = {Computer vision and machine learning tools offer an exciting new way for automatically analyzing and categorizing information from complex computer si…},
	language = {en-US},
	urldate = {2024-03-30},
	journal = {Signal Processing: Image Communication},
	author = {Bussov, Maarja and Nättilä, Joonas},
	month = nov,
	year = {2021},
	note = {Publisher: Elsevier},
	pages = {116450},
}

@article{kohonen1990,
	title = {The self-organizing map},
	volume = {78},
	issn = {1558-2256},
	url = {https://ieeexplore.ieee.org/abstract/document/58325?casa_token=tYJbvCiScXgAAAAA:e0OqIPDn1kbiKn8KQpq_5-r00iYB1fwi7ULOa4WuPC588gnVLAHVo-B8PPP2UmlgvFyr9YgEMQM},
	doi = {10.1109/5.58325},
	number = {9},
	urldate = {2024-05-15},
	journal = {Proceedings of the IEEE},
	author = {Kohonen, T.},
	month = sep,
	year = {1990},
	note = {Conference Name: Proceedings of the IEEE},
	keywords = {Animals, Artificial neural networks, Biological neural networks, Computer networks, Organizing, Pattern recognition, Process control, Signal processing, Signal processing algorithms, Speech recognition},
	pages = {1464--1480},
}

@article{ha2024,
	title = {Machine-Learning Characterization of Intermittency in Plasma Turbulence: Single and Double Sheet Structures},
	year = {2024, submitted},
	author = {Ha, Trung and Nättilä, Joonas and Davelaar, Jordy and Sironi, Lorenzo},
	journal = {Physical Review Letters},
}

@software{jax,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.3.13},
  year = {2018},
}